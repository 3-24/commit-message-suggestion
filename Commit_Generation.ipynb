{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Commit Generation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO5TLF3iyGxV1ylhsnzuyuv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNdEvLAmj3cy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b37d0e-1971-4421-b3df-6951e2cb9002"
      },
      "source": [
        "# mount drive https://datascience.stackexchange.com/questions/29480/uploading-images-folder-from-my-system-into-google-colab\n",
        "# login with your google account and type authorization code to mount on your googlbie drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "root = '/gdrive/My Drive/CS492I/project'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whIO4LYymsTf"
      },
      "source": [
        "from easydict import EasyDict\n",
        "from torchtext.legacy.data import Field\n",
        "from torchtext.vocab import vocab\n",
        "import collections\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import json"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed77rUFymouO"
      },
      "source": [
        "args = EasyDict()\n",
        "\n",
        "args.vocab_size = 50000\n",
        "args.embed_dim = 128\n",
        "args.hidden_dim = 256\n",
        "args.batch_size = 8"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKdZ2pbfzpc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de9393b-65db-4cae-df98-cc989f17ce31"
      },
      "source": [
        "src_counter = collections.Counter()\n",
        "trg_counter = collections.Counter()\n",
        "data_path = Path(root) / 'train.pkl'\n",
        "train_df = pd.read_pickle(data_path)\n",
        "\n",
        "for msg in train_df[\"commit_messsage\"]:\n",
        "  m = json.loads(msg)\n",
        "  trg_counter.update(m)\n",
        "\n",
        "for msg in train_df[\"diff\"]:\n",
        "  m = json.loads(msg)\n",
        "  src_counter.update(m)\n",
        "\n",
        "trg_vocab = vocab(trg_counter)\n",
        "print(len(trg_vocab))\n",
        "src_vocab = vocab(src_counter, min_freq=10)\n",
        "print(len(src_vocab))\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46401\n",
            "56350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ5_vSk-skkL"
      },
      "source": [
        "'''\n",
        "Reference https://github.com/jiminsun/pointer-generator/blob/master/data/vocab.py\n",
        "'''\n",
        "\n",
        "\n",
        "pad_token = '<pad>'\n",
        "unk_token = '<unk>'\n",
        "start_decode = '<start>'\n",
        "stop_decode = '<stop>'\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "  def __init__(self):\n",
        "    self._word_to_id = {}\n",
        "    self._id_to_word = []\n",
        "    self._count = 0\n",
        "\n",
        "  @classmethod\n",
        "  def from_file(cls, filename):\n",
        "    vocab = cls()\n",
        "    with open(filename, 'r') as f:\n",
        "      vocab._word_to_id = json.load(f)\n",
        "    vocab._id_to_word = [w for w, id_ in sorted(vocab._word_to_id, key=vocab._word_to_id.get, reverse=True)]\n",
        "    vocab._count = len(vocab._id_to_word)\n",
        "    return vocab\n",
        "\n",
        "  @classmethod\n",
        "  def from_counter(cls, counter, vocab_size, specials, min_freq):\n",
        "    vocab = cls()\n",
        "    word_and_freq = sorted(counter.items(), key=lambda tup: tup[0])\n",
        "    word_and_freq.sort(key=lambda tup: tup[1], reverse=True)\n",
        "\n",
        "    for w in specials:\n",
        "      vocab._word_to_id[w] = vocab._count\n",
        "      vocab.append(w)\n",
        "      vocab._count += 1\n",
        "\n",
        "    for word, freq in word_and_freq:\n",
        "      if freq < min_freq or vocab._count == vocab.size:\n",
        "        break\n",
        "      vocab._word_to_id[word] = vocab._count\n",
        "      vocab._id_to_word.append(word)\n",
        "      vocab._count += 1\n",
        "    \n",
        "    return vocab\n",
        "  \n",
        "  def save(self, filename):\n",
        "    with open(filename, 'w') as f:\n",
        "      json.dump(self._word_to_id)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self._count\n",
        "  \n",
        "  def unk(self):\n",
        "    return self._word_to_id.get(unk_token)\n",
        "\n",
        "  def word2id(self, word):\n",
        "    unk_id = self._word_to_id.get(word, self.unk())\n",
        "  \n",
        "  def id2word(self, word_id):\n",
        "    if word_id >= self.__len__():\n",
        "      raise ValueError(f\"Id not found in vocab: {word_id}\")\n",
        "  \n",
        "  def extend(self, oovs):\n",
        "    return self._id_to_word + list(oovs)\n",
        "  \n",
        "  def tokens2ids(self, tokens):\n",
        "    return [self.word2id(t) for t in tokens]\n",
        "  \n",
        "  def tokens2ids_ext(self, tokens):\n",
        "    ids = []\n",
        "    oovs = []\n",
        "    unk_id = self.unk()\n",
        "    for t in tokens:\n",
        "      t_id = self.word2id(t)\n",
        "      if t_id == unk_id:\n",
        "        if t not in oovs:\n",
        "          oovs.append(t)\n",
        "        ids.append(len(self) + oovs.index(t))\n",
        "    return ids, oovs"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slVJ13mVowV3"
      },
      "source": [
        "class Batch(object):\n",
        "  def __init__(self, data, vocab, max_decode)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}