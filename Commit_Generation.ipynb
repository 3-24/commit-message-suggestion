{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Commit Generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "44a8083fd7df4ba5a98694715e86d1a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aec930ce551c419aa1f03fe29eb6aad6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_81a8e63e046f489184be360757824d22",
              "IPY_MODEL_6a57a592f1f549068d8303144fa07958",
              "IPY_MODEL_2021a23e2bfb4746b66e7a198e545432"
            ]
          }
        },
        "aec930ce551c419aa1f03fe29eb6aad6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "81a8e63e046f489184be360757824d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f58d39571c6540218bdd5b1a30aea400",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validation sanity check:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1592c9d6dda48948a15b281f9d7a09e"
          }
        },
        "6a57a592f1f549068d8303144fa07958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ce840c1db85e4e499a943924ef0a767c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c94af5766134c50b805c03d4f75f592"
          }
        },
        "2021a23e2bfb4746b66e7a198e545432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b951c667e65543f5acf4f320c47cb7a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d70ddbb9ab664fcc9ed365d5826da7ea"
          }
        },
        "f58d39571c6540218bdd5b1a30aea400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1592c9d6dda48948a15b281f9d7a09e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce840c1db85e4e499a943924ef0a767c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c94af5766134c50b805c03d4f75f592": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b951c667e65543f5acf4f320c47cb7a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d70ddbb9ab664fcc9ed365d5826da7ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNdEvLAmj3cy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30dbeaec-902f-41ed-df02-af0b8e66310d"
      },
      "source": [
        "# mount drive https://datascience.stackexchange.com/questions/29480/uploading-images-folder-from-my-system-into-google-colab\n",
        "# login with your google account and type authorization code to mount on your googlbie drive.\n",
        "from google.colab import drive\n",
        "drive._mount('/gdrive')\n",
        "root = '/gdrive/My Drive/CS492I/project'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#import"
      ],
      "metadata": {
        "id": "1Qdmd_kIyTCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "id": "-CKe2zOQtms3",
        "outputId": "d58479ab-cde6-46e7-bf69-4959f0309def",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.7/dist-packages (1.5.5)\n",
            "Requirement already satisfied: torch>=1.7.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.10.0+cu111)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.7.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.62.3)\n",
            "Requirement already satisfied: pyDeprecate==0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.3.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.18.2)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (3.10.0.2)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2021.11.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.42.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (5.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (4.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.7.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.optim import Adagrad\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "from io import BufferedRWPair\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "jdLIFoDXsT5f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Config.py"
      ],
      "metadata": {
        "id": "0I438AwCrYEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from easydict import EasyDict\n",
        "\n",
        "args = EasyDict()\n",
        "\n",
        "args.vocab_size = 50000\n",
        "args.embed_dim = 128\n",
        "args.hidden_dim = 256\n",
        "args.batch_size = 8\n",
        "args.trg_max_len = 50\n",
        "args.learning_rate = 0.15\n",
        "args.accum_init = 0.15\n",
        "args.pad_id = 0\n",
        "args.seed = 123\n",
        "args.epochs = 10\n",
        "args.max_grad_norm = 2.0"
      ],
      "metadata": {
        "id": "FRMsQgltslB5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# vocab.py"
      ],
      "metadata": {
        "id": "TeP38-phrjYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Reference https://github.com/jiminsun/pointer-generator/blob/master/data/vocab.py\n",
        "'''\n",
        "pad_token = '<pad>'\n",
        "unk_token = '<unk>'\n",
        "start_decode = '<start>'\n",
        "stop_decode = '<stop>'\n",
        "\n",
        "class Vocab(object):\n",
        "  def __init__(self):\n",
        "    self._word_to_id = {}\n",
        "    self._id_to_word = []\n",
        "    self._count = 0\n",
        "\n",
        "  @classmethod\n",
        "  def from_file(cls, filename):\n",
        "    vocab = cls()\n",
        "    with open(filename, 'r') as f:\n",
        "      vocab._word_to_id = json.load(f)\n",
        "    vocab._id_to_word = [w for w, id_ in sorted(vocab._word_to_id, key=vocab._word_to_id.get, reverse=True)]\n",
        "    vocab._count = len(vocab._id_to_word)\n",
        "    return vocab\n",
        "\n",
        "  @classmethod\n",
        "  def from_counter(cls, counter, vocab_size, min_freq=1, specials=[pad_token, unk_token, start_decode, stop_decode]):\n",
        "    vocab = cls()\n",
        "    word_and_freq = sorted(counter.items(), key=lambda tup: tup[0])\n",
        "    word_and_freq.sort(key=lambda tup: tup[1], reverse=True)\n",
        "\n",
        "    for w in specials:\n",
        "      vocab._word_to_id[w] = vocab._count\n",
        "      vocab._id_to_word.append(w)\n",
        "      vocab._count += 1\n",
        "\n",
        "    for word, freq in word_and_freq:\n",
        "      if freq < min_freq or vocab._count == vocab_size:\n",
        "        break\n",
        "      vocab._word_to_id[word] = vocab._count\n",
        "      vocab._id_to_word.append(word)\n",
        "      vocab._count += 1\n",
        "    \n",
        "    return vocab\n",
        "  \n",
        "  def save(self, filename):\n",
        "    with open(filename, 'w') as f:\n",
        "      json.dump(self._word_to_id)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self._count\n",
        "  \n",
        "  def unk(self):\n",
        "    return self._word_to_id.get(unk_token)\n",
        "  \n",
        "  def pad(self):\n",
        "    return self._word_to_id.get(pad_token)\n",
        "  \n",
        "  def start(self):\n",
        "    return self._word_to_id.get(start_decode)\n",
        "  \n",
        "  def stop(self):\n",
        "    return self._word_to_id.get(stop_decode)\n",
        "\n",
        "  def word2id(self, word):\n",
        "    unk_id = self._word_to_id.get(word, self.unk())\n",
        "    if word in self._word_to_id:\n",
        "      return self._word_to_id[word]\n",
        "    else:\n",
        "      return unk_id\n",
        "  \n",
        "  def id2word(self, word_id):\n",
        "    if word_id >= self.__len__():\n",
        "      raise ValueError(f\"Id not found in vocab: {word_id}\")\n",
        "    return self.id_to_word[word_id]\n",
        "  \n",
        "  def extend(self, oovs):\n",
        "    return self._id_to_word + list(oovs)\n",
        "  \n",
        "  def tokens2ids(self, tokens):\n",
        "    return [self.word2id(t) for t in tokens]\n",
        "  \n",
        "  def tokens2ids_ext(self, tokens):\n",
        "    ids = []\n",
        "    oovs = []\n",
        "    unk_id = self.unk()\n",
        "    for t in tokens:\n",
        "      t_id = self.word2id(t)\n",
        "      if t_id == unk_id:\n",
        "        if t not in oovs:\n",
        "          oovs.append(t)\n",
        "        ids.append(len(self) + oovs.index(t))\n",
        "      else:\n",
        "        ids.append(t_id)\n",
        "    return ids, oovs"
      ],
      "metadata": {
        "id": "2GfT8GFi2oi7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#model.py"
      ],
      "metadata": {
        "id": "Q12oujNWr0v4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "J-SG-GK_ykct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "B : batch size\n",
        "E : embedding size\n",
        "H : encoder hidden state dimension\n",
        "L : sequence length\n",
        "T : target sequence length\n",
        "\"\"\"\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim=args.embed_dim, hidden_dim=args.hidden_dim):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_dim: source embedding dimension\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n",
        "        self.reduce_h = nn.Linear(hidden_dim * 2, hidden_dim, bias=True)\n",
        "        self.reduce_c = nn.Linear(hidden_dim * 2, hidden_dim, bias=True)\n",
        "    \n",
        "    def forward(self, src, src_lens):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: source token embeddings    [B x L x E]\n",
        "            src_lens: source text length    [B]\n",
        "        Returns:\n",
        "            enc_hidden: sequence of encoder hidden states                  [B x L x 2H]\n",
        "            (final_h, final_c): Tuple for decoder state initialization     [B x L x H]\n",
        "        \"\"\"\n",
        "\n",
        "        x = pack_padded_sequence(src, src_lens.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        output, (h, c) = self.lstm(x) # [B x L x 2H], [2 x B x H], [2 x B x H]\n",
        "        enc_hidden, _ = pad_packed_sequence(output, batch_first=True)\n",
        "\n",
        "        # Concatenate bidirectional lstm states\n",
        "        h = torch.cat((h[0], h[1]), dim=-1)  # [B x 2H]\n",
        "        c = torch.cat((c[0], c[1]), dim=-1)  # [B x 2H]\n",
        "\n",
        "        # Project to decoder hidden state size\n",
        "        final_hidden = torch.relu(self.reduce_h(h))  # [B x H]\n",
        "        final_cell = torch.relu(self.reduce_c(c))  # [B x H]\n",
        "\n",
        "        return enc_hidden, (final_hidden, final_cell)"
      ],
      "metadata": {
        "id": "M7mWZKhfyc69"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Attention"
      ],
      "metadata": {
        "id": "D7pM_IUKynfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim=args.hidden_dim):\n",
        "        super().__init__()\n",
        "        self.v = nn.Linear(hidden_dim * 2, 1, bias=False)                       # v\n",
        "        self.enc_proj = nn.Linear(hidden_dim * 2, hidden_dim * 2, bias=False)   # W_h\n",
        "        self.dec_proj = nn.Linear(hidden_dim, hidden_dim * 2, bias=True)        # W_s, b_attn\n",
        "  \n",
        "\n",
        "    def forward(self, dec_input, enc_hidden, enc_pad_mask):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dec_input: decoder hidden state             [B x H]\n",
        "            enc_hidden: encoder hidden states           [B x L x 2H]\n",
        "            enc_pad_mask: encoder padding masks         [B x L]\n",
        "        Returns:\n",
        "            attn_dist: attention dist'n over src tokens [B x L]\n",
        "        \"\"\"\n",
        "        enc_feature = self.enc_proj(enc_hidden)               # [B X L X 2H]\n",
        "        dec_feature = self.dec_proj(dec_input).unsqueeze(1)   # [B X 1 X 2H]\n",
        "        temp = torch.tanh(enc_feature + dec_feature)\n",
        "        scores = self.v(torch.tanh(enc_feature + dec_feature)).squeeze(-1)  # [B X L]\n",
        "        scores = scores.float().masked_fill_(\n",
        "            enc_pad_mask,\n",
        "            float('-inf')\n",
        "        ).type_as(scores)  # FP16 support: cast to float and back\n",
        "        \n",
        "        attn_dist = F.softmax(scores, dim=-1) # [B X L]\n",
        "\n",
        "        return attn_dist"
      ],
      "metadata": {
        "id": "_JP2mvZSywDs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##AttentionDecoderLayer"
      ],
      "metadata": {
        "id": "88PpF1WkyyG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionDecoderLayer(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, trg_vocab_size):\n",
        "    super().__init__()\n",
        "    self.lstm = nn.LSTMCell(input_size=input_dim, hidden_size=hidden_dim)\n",
        "    self.attention = Attention(hidden_dim)\n",
        "    self.l1 = nn.Linear(hidden_dim*3, hidden_dim, bias=True)    # V\n",
        "    self.l2 = nn.Linear(hidden_dim, trg_vocab_size, bias=True)  # V'\n",
        "  \n",
        "  def forward(self, dec_input, dec_hidden, dec_cell, enc_hidden, enc_pad_mask):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        dec_input: decoder input embedding at timestep t    [B x E]\n",
        "        prev_h: decoder hidden state from prev timestep     [B x H]\n",
        "        prev_c: decoder cell state from prev timestep       [B x H]\n",
        "        enc_hidden: encoder hidden states                   [B x L x 2H]\n",
        "        enc_pad_mask: encoder masks for attn computation    [B x L]\n",
        "    Returns:\n",
        "        vocab_dist: predicted vocab dist'n at timestep t    [B x V]\n",
        "        attn_dist: attention dist'n at timestep t           [B x L]\n",
        "        context_vec: context vector at timestep t           [B x 2H]\n",
        "        hidden: hidden state at timestep t                  [B x H]\n",
        "        cell: cell state at timestep t                      [B x H]\n",
        "    \"\"\"\n",
        "    h, c = self.lstm(dec_input, (dec_hidden, dec_cell))  # [B X H], [B X H]\n",
        "    attn_dist = self.attention(h, enc_hidden, enc_pad_mask)  # [B X 1 X L]\n",
        "    context_vec = torch.bmm(attn_dist.unsqueeze(1), enc_hidden).squeeze(1)  # [B X 2H] <- [B X 1 X 2H] = [B X 1 X L] @ [B X L X 2H]\n",
        "    output = self.l1(torch.cat([h, context_vec], dim = -1)) # [B X H]\n",
        "    vocab_dist = F.softmax(self.l2(output), dim=-1)              # [B X V]\n",
        "    return vocab_dist, attn_dist, context_vec, h, c"
      ],
      "metadata": {
        "id": "whXJpnQuy1X0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PointGenerator"
      ],
      "metadata": {
        "id": "_yKhp-Zny4Ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PointerGenerator(nn.Module):\n",
        "    def __init__(self, src_vocab, trg_vocab):\n",
        "        super().__init__()\n",
        "        self.src_vocab = src_vocab\n",
        "        self.trg_vocab = trg_vocab\n",
        "        embed_dim = args.embed_dim\n",
        "        self.src_embedding = nn.Embedding(len(src_vocab), embed_dim, padding_idx=src_vocab.pad())\n",
        "        self.trg_embedding = nn.Embedding(len(trg_vocab), embed_dim, padding_idx=trg_vocab.pad())\n",
        "\n",
        "\n",
        "        hidden_dim = args.hidden_dim\n",
        "        self.encoder = Encoder(input_dim=embed_dim, hidden_dim=hidden_dim)\n",
        "        self.decoder = AttentionDecoderLayer(input_dim=embed_dim, hidden_dim=hidden_dim, trg_vocab_size=len(trg_vocab))\n",
        "\n",
        "        self.w_h = nn.Linear(hidden_dim * 2, 1, bias=False)\n",
        "        self.w_s = nn.Linear(hidden_dim, 1, bias=False)\n",
        "        self.w_x = nn.Linear(embed_dim, 1, bias=True)\n",
        "\n",
        "\n",
        "    def forward(self, enc_input, enc_input_ext, enc_pad_mask, enc_len, max_oov_len, dec_input=None):\n",
        "        \"\"\"\n",
        "        Predict summary using reference summary as decoder inputs. If dec_input is not provided, then teacher forcing is disabled.\n",
        "        Args:\n",
        "            enc_input: source text id sequence                      [B x L]\n",
        "            enc_input_ext: source text id seq w/ extended vocab     [B x L]\n",
        "            enc_pad_mask: source text padding mask. [PAD] -> True   [B x L]\n",
        "            enc_len: source text length                             [B]\n",
        "            dec_input: target text id sequence                      [B x T]\n",
        "            max_oov_len: max number of oovs in src                  [1]\n",
        "        Returns:\n",
        "            final_dists: predicted dist'n using extended vocab      [B x V_x x T]\n",
        "            attn_dists: attn dist'n from each t                     [B x L x T]\n",
        "            coverages: coverage vectors from each t                 [B x L x T]\n",
        "        \"\"\"\n",
        "        batch_size = enc_input.size(0)\n",
        "        enc_emb = self.src_embedding(enc_input)             # [B X L X E]\n",
        "        enc_hidden, (h,c) = self.encoder(enc_emb, enc_len)  # [B X L X 2H], [B X L X H], [B X L X H]\n",
        "        teacher_forcing = False\n",
        "\n",
        "        if not dec_input is None:\n",
        "            teacher_forcing = True\n",
        "            dec_emb = self.trg_embedding(dec_input)             # [B X T X E]\n",
        "        else:\n",
        "            dec_prev_emb = [self.trg_embedding(self.trg_vocab().start()) for _ in range(batch_size)]  # [B X E]\n",
        "\n",
        "\n",
        "        final_dists = []\n",
        "\n",
        "        for t in range(args.trg_max_len):\n",
        "            if teacher_forcing:\n",
        "                input_t = dec_emb[:, t, :]\n",
        "            else:\n",
        "                input_t = dec_prev_emb\n",
        "            vocab_dist, attn_dist, context_vec, h, c = self.decoder(\n",
        "                dec_input=input_t, # [B x E]\n",
        "                dec_hidden=h,\n",
        "                dec_cell=c,\n",
        "                enc_hidden=enc_hidden,\n",
        "                enc_pad_mask=enc_pad_mask\n",
        "            )\n",
        "            p_gen = torch.sigmoid(self.w_h(context_vec) + self.w_s(h) + self.w_x(input_t))\n",
        "            weighted_vocab_dist = p_gen * vocab_dist\n",
        "            weighted_attn_dist = (1.0 - p_gen) * attn_dist\n",
        "            B = vocab_dist.size(0)\n",
        "            extended_vocab_dist = torch.cat([weighted_vocab_dist, torch.zeros(B, max_oov_len, device=vocab_dist.device)], dim=-1)\n",
        "            final_dist = extended_vocab_dist.scatter_add(dim=-1, index=enc_input_ext, src=weighted_attn_dist) # [B X V_]\n",
        "            final_dists.append(final_dist)\n",
        "            if (not teacher_forcing):\n",
        "                highest_prob = torch.argmax(final_dist, dim=1)                              # [B]\n",
        "                highest_prob[highest_prob >= len(self.trg_vocab)] = self.trg_vocab.unk()\n",
        "                dec_prev_emb = self.trg_embedding(B)        #[B X E]\n",
        "        return final_dists"
      ],
      "metadata": {
        "id": "ukn917NAy8tv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SummarizationModel"
      ],
      "metadata": {
        "id": "USCybTg9y-S2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SummarizationModel(pl.LightningModule):\n",
        "    def __init__(self, src_vocab, trg_vocab):\n",
        "        super().__init__()\n",
        "        self.vocab = trg_vocab\n",
        "        self.model = PointerGenerator(src_vocab, trg_vocab)\n",
        "        self.num_step = 0\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        output = self.model.forward(\n",
        "            enc_input=batch.enc_input,\n",
        "            enc_input_ext=batch.enc_input_ext,\n",
        "            enc_pad_mask=batch.enc_pad_mask,\n",
        "            enc_len=batch.enc_len,\n",
        "            dec_input=batch.dec_input,\n",
        "            max_oov_len=batch.max_oov_len)\n",
        "        \n",
        "        dec_target = batch.dec_target\n",
        "        loss = F.nll_loss(torch.log(output), dec_target, ignore_index=args.pad_id, reduction='mean')\n",
        "        self.logger.log_metrics({\"train_loss\": loss}, self.num_step)\n",
        "        self.num_step += 1\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        output = self.model.forward(\n",
        "            enc_input=batch.enc_input,\n",
        "            enc_input_ext=batch.enc_input_ext,\n",
        "            enc_pad_mask=batch.enc_pad_mask,\n",
        "            enc_len=batch.enc_len,\n",
        "            dec_input=batch.dec_input,\n",
        "            max_oov_len=batch.max_oov_len)\n",
        "        \n",
        "        dec_target = batch.dec_target\n",
        "        loss = F.nll_loss(\n",
        "            torch.log(output), dec_target, ignore_index=args.pad_id, reduction='mean')\n",
        "        self.log('val_loss', loss, on_step=True, on_epoch=False, prog_bar=False, logger=True)\n",
        "        self.logger.log_metrics({'val_loss': loss}, self.num_step)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        output = self.model.forward(\n",
        "            enc_input=batch.enc_input,\n",
        "            enc_input_ext=batch.enc_input_ext,\n",
        "            enc_pad_mask=batch.enc_pad_mask,\n",
        "            enc_len=batch.enc_len,\n",
        "            max_oov_len=batch.max_oov_len\n",
        "        )\n",
        "        # TODO: FIXHERE\n",
        "        result = {}\n",
        "        result['target'] = output\n",
        "        result['source'] = [' '.join(w) for w in batch.src_text]\n",
        "        result['real_target'] = [' '.join(w) for w in batch.tgt_text]\n",
        "        return result\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        return Adagrad(self.parameters(), lr=args.learning_rate, initial_accumulator_value=args.accum_init)\n",
        "\n"
      ],
      "metadata": {
        "id": "Y6vs7LpAseSv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#data.py"
      ],
      "metadata": {
        "id": "og6vBwQvx5S_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CommitDataset"
      ],
      "metadata": {
        "id": "OFXr6SA0zFEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CommitDataset(Dataset):\n",
        "    def __init__(self, src_vocab: Vocab, trg_vocab: Vocab, file_path):\n",
        "        self.src_vocab = src_vocab\n",
        "        self.trg_vocab = trg_vocab\n",
        "        self.df = pd.read_pickle(file_path)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        item = EasyDict()\n",
        "        row = self.df.iloc[index]\n",
        "        src = json.loads(row[\"commit_messsage\"])\n",
        "        trg = json.loads(row[\"diff\"])\n",
        "        trg[0:0] = [self.trg_vocab.start()]\n",
        "        trg.append(self.trg_vocab.stop())\n",
        "        item.src_ids = self.src_vocab.tokens2ids(src)\n",
        "        item.src_ids_ext, item.oovs = self.src_vocab.tokens2ids_ext(src)\n",
        "        item.trg_ids = self.trg_vocab.tokens2ids(trg)\n",
        "        \n",
        "        return item\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ],
      "metadata": {
        "id": "4AZqWt1ksegd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CommitCollate"
      ],
      "metadata": {
        "id": "EapC73qczHGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CommitCollate(batchdata):\n",
        "    size = len(batchdata)\n",
        "    max_enc_len, max_dec_len,max_oov_len = 0,0,0\n",
        "    enc_len_list = [len(batchdata[i]['src_ids']) for i in range(size)]\n",
        "    for i in range(size):\n",
        "        max_enc_len = max(len(batchdata[i]['src_ids']),max_enc_len)\n",
        "        max_dec_len = max(len(batchdata[i]['trg_ids']),max_dec_len)\n",
        "        max_oov_len = max(len(batchdata[i]['oovs']),max_oov_len)\n",
        "    \n",
        "    for i in range(len(batchdata)):\n",
        "        batchdata[i]['src_ids'] += [0]*(max_enc_len-len(batchdata[i]['src_ids']))\n",
        "        batchdata[i]['src_ids_ext'] += [0]*(max_enc_len-len(batchdata[i]['src_ids_ext']))\n",
        "        batchdata[i]['trg_ids'] += [0]*(max_dec_len-len(batchdata[i]['trg_ids']))\n",
        "    batch = EasyDict()\n",
        "    batch.enc_input = torch.LongTensor([batchdata[i]['src_ids'] for i in range(size)])\n",
        "    batch.enc_input_ext = torch.LongTensor([batchdata[i]['src_ids_ext'] for i in range(size)])\n",
        "    batch.enc_pad_mask = (batch.enc_input == 0)\n",
        "    batch.enc_len = torch.LongTensor(enc_len_list)\n",
        "    batch.dec_input = torch.LongTensor([batchdata[i]['trg_ids'] for i in range(size)])\n",
        "    batch.max_oov_len = max_oov_len\n",
        "    return batch"
      ],
      "metadata": {
        "id": "aya06JSFzNXh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train.py"
      ],
      "metadata": {
        "id": "pIQq7XRwsGkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(root):\n",
        "    pl.seed_everything(args.seed)\n",
        "\n",
        "    src_counter = Counter()\n",
        "    trg_counter = Counter()\n",
        "    train_path = Path(root) / 'train.pkl'\n",
        "    validation_path = Path(root) / 'validation.pkl'\n",
        "    test_path = Path(root) / 'test.pkl'\n",
        "    train_df = pd.read_pickle(train_path)\n",
        "\n",
        "    for msg in train_df[\"diff\"]:\n",
        "        m = json.loads(msg)\n",
        "        src_counter.update(m)\n",
        "\n",
        "    for msg in train_df[\"commit_messsage\"]:\n",
        "        m = json.loads(msg)\n",
        "        trg_counter.update(m)\n",
        "\n",
        "    src_vocab = Vocab.from_counter(\n",
        "        counter=src_counter, \n",
        "        vocab_size=args.vocab_size\n",
        "    )\n",
        "\n",
        "    trg_vocab = Vocab.from_counter(\n",
        "        counter=trg_counter, \n",
        "        vocab_size=args.vocab_size\n",
        "    )\n",
        "\n",
        "    model = SummarizationModel(src_vocab, trg_vocab)\n",
        "\n",
        "    trainer = pl.Trainer(\n",
        "        gpus=torch.cuda.device_count(),\n",
        "        max_epochs=args.epochs,\n",
        "        gradient_clip_val=args.max_grad_norm\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        CommitDataset(src_vocab, trg_vocab, train_path),\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=CommitCollate\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        CommitDataset(src_vocab, trg_vocab, validation_path),\n",
        "        batch_size=args.batch_size,\n",
        "        collate_fn=CommitCollate,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    trainer.fit(model, train_loader, val_loader)\n",
        "\n",
        "train(root)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644,
          "referenced_widgets": [
            "44a8083fd7df4ba5a98694715e86d1a1",
            "aec930ce551c419aa1f03fe29eb6aad6",
            "81a8e63e046f489184be360757824d22",
            "6a57a592f1f549068d8303144fa07958",
            "2021a23e2bfb4746b66e7a198e545432",
            "f58d39571c6540218bdd5b1a30aea400",
            "c1592c9d6dda48948a15b281f9d7a09e",
            "ce840c1db85e4e499a943924ef0a767c",
            "9c94af5766134c50b805c03d4f75f592",
            "b951c667e65543f5acf4f320c47cb7a4",
            "d70ddbb9ab664fcc9ed365d5826da7ea"
          ]
        },
        "id": "cpdfuuRBse0c",
        "outputId": "38eb7674-cd3b-475d-cd67-eb17deb46f45"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 123\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "\n",
            "  | Name  | Type             | Params\n",
            "-------------------------------------------\n",
            "0 | model | PointerGenerator | 26.3 M\n",
            "-------------------------------------------\n",
            "26.3 M    Trainable params\n",
            "0         Non-trainable params\n",
            "26.3 M    Total params\n",
            "105.225   Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44a8083fd7df4ba5a98694715e86d1a1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-62cc8d5f5e54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-62cc8d5f5e54>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(root)\u001b[0m\n\u001b[1;32m     48\u001b[0m     )\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0mtrain_dataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m         self._call_and_handle_interrupt(\n\u001b[0;32m--> 738\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m         )\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \"\"\"\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m         \u001b[0;31m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;31m# TODO: ckpt_path only in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0mckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpt_path\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1307\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m         \u001b[0;31m# enable train mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m   1369\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_sanity_check_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mdl_max_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataloader_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mdl_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_max_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_dataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# store batch level output per dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher, dataloader_idx, dl_max_batches, num_dataloaders)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# lightning module methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"evaluation_step_and_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\u001b[0m in \u001b[0;36m_evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, step_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \"\"\"\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSTEP_OUTPUT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-495d2fa6ac7e>\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0menc_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mdec_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             max_oov_len=batch.max_oov_len)\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mdec_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-6db79098d751>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, enc_input, enc_input_ext, enc_pad_mask, enc_len, max_oov_len, dec_input)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mextended_vocab_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweighted_vocab_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_oov_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mfinal_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextended_vocab_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc_input_ext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweighted_attn_dist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [B X V_]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mfinal_dists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mteacher_forcing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: index 50000 is out of bounds for dimension 1 with size 46406"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8Pxk0mkNse8f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}