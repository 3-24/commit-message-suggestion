{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "TySV2A3KyKzL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TySV2A3KyKzL",
    "outputId": "5cf8dcf6-30e9-44fd-a9e0-32cf5675e7bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# mount drive https://datascience.stackexchange.com/questions/29480/uploading-images-folder-from-my-system-into-google-colab\n",
    "# login with your google account and type authorization code to mount on your googlbie drive.\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "root = '/gdrive/My Drive/CS492I/project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87dd4f62",
   "metadata": {
    "id": "87dd4f62"
   },
   "outputs": [],
   "source": [
    "root = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ade31",
   "metadata": {
    "id": "8a5ade31"
   },
   "source": [
    "## 1. Collect CodeSearchNet Repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06bb109",
   "metadata": {
    "id": "c06bb109"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "pd.set_option('max_colwidth',300)\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50cf9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c50cf9b",
    "outputId": "62b49b1b-cc12-44cd-beae-68503a6886e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-03 07:32:59--  https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/python.zip\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.69.238\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.69.238|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 940909997 (897M) [application/zip]\n",
      "Saving to: ‘python.zip’\n",
      "\n",
      "python.zip          100%[===================>] 897.32M  65.4MB/s    in 13s     \n",
      "\n",
      "2021-12-03 07:33:12 (68.1 MB/s) - ‘python.zip’ saved [940909997/940909997]\n",
      "\n",
      "Archive:  python.zip\n",
      "   creating: CodeSearchNet/python/\n",
      "   creating: CodeSearchNet/python/final/\n",
      "   creating: CodeSearchNet/python/final/jsonl/\n",
      "   creating: CodeSearchNet/python/final/jsonl/train/\n",
      "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_9.jsonl.gz  \n",
      "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_12.jsonl.gz  \n",
      "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_10.jsonl.gz  \n",
      "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_0.jsonl.gz  \n",
      "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_6.jsonl.gz  \n",
      "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_2.jsonl.gz  \n",
      "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_4.jsonl.gz  \n",
      "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_8.jsonl.gz  \n",
      "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_11.jsonl.gz  \n",
      "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_5.jsonl.gz  \n",
      "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_13.jsonl.gz  \n",
      "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_3.jsonl.gz  \n",
      "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_1.jsonl.gz  \n",
      "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_7.jsonl.gz  \n",
      "   creating: CodeSearchNet/python/final/jsonl/test/\n",
      "  inflating: CodeSearchNet/python/final/jsonl/test/python_test_0.jsonl.gz  \n",
      "   creating: CodeSearchNet/python/final/jsonl/valid/\n",
      "  inflating: CodeSearchNet/python/final/jsonl/valid/python_valid_0.jsonl.gz  \n",
      "  inflating: CodeSearchNet/python_dedupe_definitions_v2.pkl  \n",
      "  inflating: CodeSearchNet/python_licenses.pkl  \n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/python.zip\n",
    "!mkdir CodeSearchNet\n",
    "!unzip python.zip -d CodeSearchNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2847085c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2847085c",
    "outputId": "b98d532c-a88f-43db-c790-a0986fdddffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('CodeSearchNet/python/final/jsonl/test/python_test_0.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_0.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_1.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_10.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_11.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_12.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_13.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_2.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_3.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_4.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_5.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_6.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_7.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_8.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_9.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/valid/python_valid_0.jsonl.gz')]\n"
     ]
    }
   ],
   "source": [
    "python_files = sorted(Path('CodeSearchNet/python').glob('**/*.gz'))\n",
    "print(python_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa7dbe1",
   "metadata": {
    "id": "8aa7dbe1"
   },
   "outputs": [],
   "source": [
    "columns_long_list = ['repo', 'path', 'url', 'code', \n",
    "                     'code_tokens', 'docstring', 'docstring_tokens', \n",
    "                     'language', 'partition']\n",
    "\n",
    "def jsonl_list_to_dataframe(file_list, columns=columns_long_list):\n",
    "    \"\"\"Load a list of jsonl.gz files into a pandas DataFrame.\"\"\"\n",
    "    return pd.concat([pd.read_json(f, \n",
    "                                   orient='records', \n",
    "                                   compression='gzip',\n",
    "                                   lines=True)[columns] \n",
    "                      for f in file_list], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6c1c77",
   "metadata": {
    "id": "be6c1c77"
   },
   "outputs": [],
   "source": [
    "pydf = jsonl_list_to_dataframe(python_files, columns=['repo'])\n",
    "pydf = pydf.drop_duplicates().reset_index(drop=True)\n",
    "pydf.to_pickle(f\"{root}/repos.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0559c4",
   "metadata": {
    "id": "1d0559c4"
   },
   "source": [
    "## 2. Collect diff and commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ee24339",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ee24339",
    "outputId": "6d87298c-387e-479a-e0b5-1a7ebcb32c97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydriller in /usr/local/lib/python3.7/dist-packages (2.0)\n",
      "Requirement already satisfied: gitpython in /usr/local/lib/python3.7/dist-packages (from pydriller) (3.1.24)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from pydriller) (2018.9)\n",
      "Requirement already satisfied: lizard in /usr/local/lib/python3.7/dist-packages (from pydriller) (1.17.9)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython->pydriller) (4.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython->pydriller) (3.10.0.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython->pydriller) (5.0.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydriller\n",
    "!pip install pandas\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72e76292",
   "metadata": {
    "id": "72e76292"
   },
   "outputs": [],
   "source": [
    "from pydriller import *\n",
    "import pandas as pd\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "import re\n",
    "from itertools import chain\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "845d5eb7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "845d5eb7",
    "outputId": "a229dce8-6f96-486e-a92d-efeb80a7de27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13590, 1)\n",
      "                                 repo\n",
      "0                     soimort/you-get\n",
      "1                      apache/airflow\n",
      "2                      pytorch/vision\n",
      "3                      asciimoo/searx\n",
      "4              tensorflow/probability\n",
      "...                               ...\n",
      "13585         praekelt/python-ambient\n",
      "13586                 zenreach/py-era\n",
      "13587  TakesxiSximada/custom_settings\n",
      "13588            openpermissions/bass\n",
      "13589               xnuinside/clifier\n",
      "\n",
      "[13590 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "repodf = pd.read_pickle(f\"{root}/repos.pkl\")\n",
    "print(repodf.shape)\n",
    "print(repodf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "449680fc",
   "metadata": {
    "id": "449680fc"
   },
   "outputs": [],
   "source": [
    "def basic_filter(message):\n",
    "    return message.split(\"\\n\", 1)[0].strip()\n",
    "\n",
    "# Remove [label] in front of commit if exists\n",
    "def label_filter(message):\n",
    "    if (message.startswith('[')):\n",
    "        end_bracket_index = message.find(']')\n",
    "        if (end_bracket_index == -1):\n",
    "            return None\n",
    "        return message[end_bracket_index+1:]\n",
    "    return message\n",
    "\n",
    "def camel_case_split(str):\n",
    "    return re.findall(r'[A-Z](?:[a-z]+|[A-Z]*(?=[A-Z]|$))', str)\n",
    "\n",
    "def case_splitter(token):\n",
    "    return list(map(lambda x: x.lower(), camel_case_split(token[0].upper() + token[1:]) if token[0].isalpha() else [token]))\n",
    "\n",
    "\n",
    "def split_by_quote(diff):\n",
    "    text_list = [(0,0)]\n",
    "    quote_state = 0 #[\"out\",\"single\",\"double\",\"Single\",\"Double\",\"quote\"]\n",
    "    i=0\n",
    "    while i<len(diff):\n",
    "      if diff[i] == \"\\\\\":i+=1\n",
    "      elif (diff[i] == \"\\n\" and quote_state == 5) or (diff[i] == '#' and quote_state == 0):\n",
    "        text_list.append((quote_state,i))\n",
    "        quote_state = abs(5-quote_state)\n",
    "      elif diff[i] == '\"':\n",
    "        if i+2<len(diff) and diff[i:i+3]=='\"\"\"' and (quote_state == 0 or quote_state ==4):\n",
    "          text_list.append((quote_state,i+max(quote_state-1,0)))\n",
    "          quote_state = abs(4-quote_state)\n",
    "          i+=2\n",
    "        elif quote_state == 0 or quote_state == 2:\n",
    "          text_list.append((quote_state,i+max(quote_state-1,0)))\n",
    "          quote_state = abs(2-quote_state)\n",
    "      elif diff[i] == \"'\":\n",
    "        if i+2<len(diff) and diff[i:i+3] == \"'''\" and (quote_state == 0 or quote_state == 3):\n",
    "          text_list.append((quote_state,i+quote_state))\n",
    "          quote_state = abs(3-quote_state)\n",
    "          i+=2\n",
    "        elif quote_state == 0 or quote_state == 1:\n",
    "          text_list.append((quote_state,i+quote_state))\n",
    "          quote_state = abs(1-quote_state)\n",
    "      i+=1\n",
    "    text_list.append((quote_state,i))\n",
    "    return [(text_list[i][0]==0,diff[text_list[i-1][1]:text_list[i][1]]) for i in range(1,len(text_list))]\n",
    "  \n",
    "\n",
    "token_regex = r\"\"\"(?x)\n",
    "<(?:add|del)>   #Filtered eariler\n",
    "|(?:[-+*/^&~|=%!<>@?$][\\s]*)+     #Sequence of symbols\n",
    "|[\\n]                    #Change row\n",
    "|[a-zA-Z]+               #General text\n",
    "|[0-9]+                  #Number\n",
    "\"\"\"\n",
    "string_regex = r\"\"\"(?x)\n",
    "<(?:add|del)>\n",
    "|[\\n]\n",
    "|[a-zA-Z]+\n",
    "\"\"\"\n",
    "def diff_tokenizer(diff_text):\n",
    "    diff = '\\n'.join(map(lambda x: x[1], filter(lambda y: y[0] % 2 == 0, enumerate(diff_text.split(\"@@\")))))\n",
    "    diff = diff.replace('\\n+', '\\n<add>').replace('\\n-', '\\n<del>')\n",
    "    diff = re.sub(r\"(?:\\n[ \\t\\r\\f\\v]*)+\",\"\\n\",diff) # Join continuous row change\n",
    "    quote_split = split_by_quote(diff)\n",
    "    token_initial = chain.from_iterable(map(lambda a: regexp_tokenize(a[1],(token_regex if a[0] else string_regex)), quote_split))\n",
    "    token_camel_case_split = chain.from_iterable(map(case_splitter, token_initial))\n",
    "    return token_camel_case_split\n",
    "\n",
    "\n",
    "def commit_msg_tokenizer(msg):\n",
    "    line = basic_filter(msg)\n",
    "    line = label_filter(line)\n",
    "    if (line is None):\n",
    "        return None\n",
    "    if line.count(\"`\")%2 == 1:\n",
    "        return None\n",
    "    \n",
    "    backtick_regex = r\"`[^`]+`|[^`]+\"\n",
    "    line_divided_by_backtick = re.findall(backtick_regex,line)\n",
    "    tokens = chain.from_iterable(map(lambda text: regexp_tokenize(text,(token_regex if text[0] == '`' else string_regex)),line_divided_by_backtick))\n",
    "    commit_tokens = list(chain.from_iterable(map(case_splitter, tokens)))\n",
    "    if (len(commit_tokens) < 3 or len(commit_tokens) > 30):\n",
    "        return None\n",
    "    if (\"version\" in commit_tokens):\n",
    "        return None\n",
    "    return commit_tokens\n",
    "\n",
    "def parse_repo_commits(repo_name, commit_limit=50):\n",
    "    data = []\n",
    "    commit_count = 0\n",
    "    commit_count_traversed = 0\n",
    "    try:\n",
    "      for commit in Repository(\n",
    "          f\"https://github.com/{repo_name}\",\n",
    "          only_modifications_with_file_types=[\".py\"],\n",
    "          only_no_merge=True,\n",
    "          order='reverse'\n",
    "      ).traverse_commits():\n",
    "          commit_count_traversed += 1\n",
    "          if (commit_count >= commit_limit): break\n",
    "          \n",
    "          commit_tokens = commit_msg_tokenizer(commit.msg)\n",
    "          if (commit_tokens is None):\n",
    "              continue\n",
    "          \n",
    "          # Check if changed files are python\n",
    "          file_failed = False\n",
    "          count_diff_lines = 0\n",
    "\n",
    "          for mf in commit.modified_files:\n",
    "              if (not mf.filename.endswith(\".py\")):\n",
    "                  file_failed = True\n",
    "                  break\n",
    "              count_diff_lines += mf.added_lines + mf.deleted_lines\n",
    "          \n",
    "          if (file_failed):\n",
    "              continue\n",
    "          \n",
    "          if (count_diff_lines > 50):\n",
    "              continue\n",
    "          \n",
    "          # Create diff tokens\n",
    "          diff_tokens = []\n",
    "          for f in commit.modified_files:\n",
    "            diff_tokens.append (['<file>'])\n",
    "            diff_tokens.append(diff_tokenizer(f.diff))\n",
    "\n",
    "          diff_whole_tokens = list(chain.from_iterable(diff_tokens))\n",
    "\n",
    "          data.append([repo_name, commit.hash, json.dumps(commit_tokens), json.dumps(diff_whole_tokens)])\n",
    "          commit_count += 1\n",
    "        \n",
    "      \n",
    "      print(f\"[DEBUG] {repo_name}: {len(data)} / {commit_count_traversed}\")\n",
    "      return pd.DataFrame(data, columns=[\"repo\", \"hash\", \"commit_messsage\", \"diff\"])\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "      print(repo_name)\n",
    "      return pd.DataFrame([], columns=[\"repo\", \"hash\", \"commit_messsage\", \"diff\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2854419",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "b2854419",
    "outputId": "a8190f03-ed68-429c-9cff-c487667f83e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] openthread/openthread: 50 / 102\n",
      "18.134236812591553\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>hash</th>\n",
       "      <th>commit_messsage</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openthread/openthread</td>\n",
       "      <td>b2c0c1a2af710225949f35ceb2af94504808796e</td>\n",
       "      <td>[\"use\", \"xa\", \"instead\", \"of\", \"dd\", \"in\", \"th...</td>\n",
       "      <td>[\"&lt;file&gt;\", \"\\n\", \"class\", \"test\", \"dnssd\", \"se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openthread/openthread</td>\n",
       "      <td>775c568286d22268def6ffd7da3723a938825259</td>\n",
       "      <td>[\"fix\", \"failing\", \"thread\", \"cert\", \"tests\"]</td>\n",
       "      <td>[\"&lt;file&gt;\", \"\\n\", \"class\", \"open\", \"thread\", \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openthread/openthread</td>\n",
       "      <td>2d16fa25e4ec8ff1309400e1ae7548345a4335b9</td>\n",
       "      <td>[\"fix\", \"test\", \"publish\", \"meshcop\", \"service...</td>\n",
       "      <td>[\"&lt;file&gt;\", \"\\n\", \"class\", \"publish\", \"mesh\", \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>openthread/openthread</td>\n",
       "      <td>02d29cd5e343c3eb17840251b7feaa9345892895</td>\n",
       "      <td>[\"update\", \"meshcop\", \"service\", \"test\", \"case\"]</td>\n",
       "      <td>[\"&lt;file&gt;\", \"\\n\", \"class\", \"publish\", \"mesh\", \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>openthread/openthread</td>\n",
       "      <td>cf4b71d8b90122f753486215557af46b25bc2185</td>\n",
       "      <td>[\"fix\", \"issue\", \"with\", \"not\", \"initialized\",...</td>\n",
       "      <td>[\"&lt;file&gt;\", \"\\n\", \"class\", \"open\", \"thread\", \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>openthread/openthread</td>\n",
       "      <td>3dd184a0bc9577c2135f547fe16cd72454f6db26</td>\n",
       "      <td>[\"verify\", \"the\", \"number\", \"of\", \"published\",...</td>\n",
       "      <td>[\"&lt;file&gt;\", \"\\n\", \"class\", \"publish\", \"mesh\", \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>openthread/openthread</td>\n",
       "      <td>0e8b6604cb256cef828a0ebb37bdd031cdf0677d</td>\n",
       "      <td>[\"add\", \"set\", \"ccm\", \"state\", \"method\", \"in\",...</td>\n",
       "      <td>[\"&lt;file&gt;\", \"\\n\", \"class\", \"open\", \"thread\", \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>openthread/openthread</td>\n",
       "      <td>e67f432284914aa6d2675a2df0507f44aa4a0e92</td>\n",
       "      <td>[\"fix\", \"for\", \"grl\", \"th\", \"leader\", \"leader\"]</td>\n",
       "      <td>[\"&lt;file&gt;\", \"\\n\", \"class\", \"open\", \"thread\", \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>openthread/openthread</td>\n",
       "      <td>130957d48981c1294c8fc90d51556134cf935d6f</td>\n",
       "      <td>[\"fix\", \"issue\", \"with\", \"is\", \"power\", \"down\"...</td>\n",
       "      <td>[\"&lt;file&gt;\", \"\\n\", \"class\", \"open\", \"thread\", \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>openthread/openthread</td>\n",
       "      <td>825227a71a6c70f8b046f5c66a91cde8abd14757</td>\n",
       "      <td>[\"fix\", \"mdns\", \"query\"]</td>\n",
       "      <td>[\"&lt;file&gt;\", \"\\n\", \"eof\", \"\\n\", \"print\", \"mdns\",...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    repo                                      hash  \\\n",
       "0  openthread/openthread  b2c0c1a2af710225949f35ceb2af94504808796e   \n",
       "1  openthread/openthread  775c568286d22268def6ffd7da3723a938825259   \n",
       "2  openthread/openthread  2d16fa25e4ec8ff1309400e1ae7548345a4335b9   \n",
       "3  openthread/openthread  02d29cd5e343c3eb17840251b7feaa9345892895   \n",
       "4  openthread/openthread  cf4b71d8b90122f753486215557af46b25bc2185   \n",
       "5  openthread/openthread  3dd184a0bc9577c2135f547fe16cd72454f6db26   \n",
       "6  openthread/openthread  0e8b6604cb256cef828a0ebb37bdd031cdf0677d   \n",
       "7  openthread/openthread  e67f432284914aa6d2675a2df0507f44aa4a0e92   \n",
       "8  openthread/openthread  130957d48981c1294c8fc90d51556134cf935d6f   \n",
       "9  openthread/openthread  825227a71a6c70f8b046f5c66a91cde8abd14757   \n",
       "\n",
       "                                     commit_messsage  \\\n",
       "0  [\"use\", \"xa\", \"instead\", \"of\", \"dd\", \"in\", \"th...   \n",
       "1      [\"fix\", \"failing\", \"thread\", \"cert\", \"tests\"]   \n",
       "2  [\"fix\", \"test\", \"publish\", \"meshcop\", \"service...   \n",
       "3   [\"update\", \"meshcop\", \"service\", \"test\", \"case\"]   \n",
       "4  [\"fix\", \"issue\", \"with\", \"not\", \"initialized\",...   \n",
       "5  [\"verify\", \"the\", \"number\", \"of\", \"published\",...   \n",
       "6  [\"add\", \"set\", \"ccm\", \"state\", \"method\", \"in\",...   \n",
       "7    [\"fix\", \"for\", \"grl\", \"th\", \"leader\", \"leader\"]   \n",
       "8  [\"fix\", \"issue\", \"with\", \"is\", \"power\", \"down\"...   \n",
       "9                           [\"fix\", \"mdns\", \"query\"]   \n",
       "\n",
       "                                                diff  \n",
       "0  [\"<file>\", \"\\n\", \"class\", \"test\", \"dnssd\", \"se...  \n",
       "1  [\"<file>\", \"\\n\", \"class\", \"open\", \"thread\", \"t...  \n",
       "2  [\"<file>\", \"\\n\", \"class\", \"publish\", \"mesh\", \"...  \n",
       "3  [\"<file>\", \"\\n\", \"class\", \"publish\", \"mesh\", \"...  \n",
       "4  [\"<file>\", \"\\n\", \"class\", \"open\", \"thread\", \"t...  \n",
       "5  [\"<file>\", \"\\n\", \"class\", \"publish\", \"mesh\", \"...  \n",
       "6  [\"<file>\", \"\\n\", \"class\", \"open\", \"thread\", \"t...  \n",
       "7  [\"<file>\", \"\\n\", \"class\", \"open\", \"thread\", \"t...  \n",
       "8  [\"<file>\", \"\\n\", \"class\", \"open\", \"thread\", \"t...  \n",
       "9  [\"<file>\", \"\\n\", \"eof\", \"\\n\", \"print\", \"mdns\",...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "#df = parse_repo_commits(\"soimort/you-get\")\n",
    "df = parse_repo_commits(\"openthread/openthread\")\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3Dn9Co_Izwuf",
   "metadata": {
    "id": "3Dn9Co_Izwuf"
   },
   "source": [
    "# 3. Create whole dataset via Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f65faf9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0f65faf9",
    "outputId": "bb002820-6f24-4fb3-e52d-ea9367bdaadf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] google/gin-config: 50 / 100\n",
      "google/gin-config took 4.605971574783325 seconds\n",
      "[DEBUG] soimort/you-get: 50 / 80\n",
      "soimort/you-get took 4.985018968582153 seconds\n",
      "[DEBUG] graphql-python/graphene-sqlalchemy: 50 / 101\n",
      "graphql-python/graphene-sqlalchemy took 5.735839366912842 seconds\n",
      "[DEBUG] SectorLabs/django-postgres-extra: 50 / 115\n",
      "SectorLabs/django-postgres-extra took 5.8941333293914795 seconds\n",
      "[DEBUG] alpacahq/alpaca-trade-api-python: 50 / 117\n",
      "alpacahq/alpaca-trade-api-python took 6.626330614089966 seconds\n",
      "[DEBUG] ekzhu/datasketch: 46 / 155\n",
      "ekzhu/datasketch took 9.250780582427979 seconds\n",
      "[DEBUG] mopidy/mopidy-spotify: 50 / 105\n",
      "mopidy/mopidy-spotify took 5.615523815155029 seconds\n",
      "[DEBUG] ansible/ansible-lint: 50 / 107\n",
      "ansible/ansible-lint took 10.703679084777832 seconds\n",
      "[DEBUG] mozilla-iot/webthing-python: 20 / 76\n",
      "mozilla-iot/webthing-python took 4.888516664505005 seconds\n",
      "[DEBUG] Tivix/django-rest-auth: 50 / 85\n",
      "Tivix/django-rest-auth took 6.132741212844849 seconds\n",
      "[DEBUG] python/performance: 50 / 120\n",
      "python/performance took 10.04507851600647 seconds\n",
      "[DEBUG] scrapinghub/dateparser: 50 / 95\n",
      "scrapinghub/dateparser took 11.047941207885742 seconds\n",
      "[DEBUG] asciimoo/searx: 50 / 94\n",
      "asciimoo/searx took 19.787007570266724 seconds\n",
      "[DEBUG] savoirfairelinux/num2words: 50 / 94\n",
      "savoirfairelinux/num2words took 5.454126596450806 seconds\n",
      "[DEBUG] Microsoft/botbuilder-python: 50 / 115\n",
      "Microsoft/botbuilder-python took 13.390256643295288 seconds\n",
      "[DEBUG] instagrambot/instabot: 50 / 136\n",
      "instagrambot/instabot took 24.410245418548584 seconds\n",
      "[DEBUG] geopython/OWSLib: 50 / 104\n",
      "geopython/OWSLib took 10.625431776046753 seconds\n",
      "[DEBUG] chaoss/grimoirelab-perceval: 50 / 117\n",
      "chaoss/grimoirelab-perceval took 11.36008906364441 seconds\n",
      "[DEBUG] streamlink/streamlink: 50 / 114\n",
      "streamlink/streamlink took 29.265567541122437 seconds\n",
      "[DEBUG] kennethreitz/twitter-scraper: 50 / 72\n",
      "kennethreitz/twitter-scraper took 4.896889925003052 seconds\n",
      "[DEBUG] yandex/yandex-tank: 50 / 100\n",
      "yandex/yandex-tank took 12.989768981933594 seconds\n",
      "[DEBUG] mordred-descriptor/mordred: 50 / 132\n",
      "mordred-descriptor/mordred took 9.302182912826538 seconds\n",
      "[DEBUG] celiao/tmdbsimple: 50 / 142\n",
      "celiao/tmdbsimple took 6.240023136138916 seconds\n",
      "[DEBUG] williamFalcon/test-tube: 50 / 103\n",
      "williamFalcon/test-tube took 5.139984846115112 seconds\n",
      "[DEBUG] bloomreach/s4cmd: 29 / 56\n",
      "bloomreach/s4cmd took 3.805893659591675 seconds\n",
      "[DEBUG] deepmipt/DeepPavlov: 50 / 165\n",
      "deepmipt/DeepPavlov took 36.990328788757324 seconds\n",
      "[DEBUG] rsennrich/Bleualign: 48 / 78\n",
      "rsennrich/Bleualign took 5.52712607383728 seconds\n",
      "[DEBUG] Danielhiversen/PyXiaomiGateway: 50 / 80\n",
      "Danielhiversen/PyXiaomiGateway took 3.803407669067383 seconds\n",
      "[DEBUG] rollbar/pyrollbar: 50 / 71\n",
      "rollbar/pyrollbar took 5.358393669128418 seconds\n",
      "[DEBUG] bluedisk/hangul-toolkit: 6 / 16\n",
      "bluedisk/hangul-toolkit took 1.445683479309082 seconds\n",
      "[DEBUG] CITGuru/PyInquirer: 27 / 56\n",
      "CITGuru/PyInquirer took 3.14143443107605 seconds\n",
      "[DEBUG] nvdv/vprof: 50 / 97\n",
      "nvdv/vprof took 5.987940311431885 seconds\n",
      "[DEBUG] ralphbean/bugwarrior: 50 / 83\n",
      "ralphbean/bugwarrior took 5.223360538482666 seconds\n",
      "[DEBUG] pltrdy/rouge: 26 / 41\n",
      "pltrdy/rouge took 2.2202186584472656 seconds\n",
      "[DEBUG] lensacom/sparkit-learn: 50 / 80\n",
      "lensacom/sparkit-learn took 4.149223327636719 seconds\n",
      "[DEBUG] PyCQA/pylint: 50 / 193\n",
      "PyCQA/pylint took 29.97547674179077 seconds\n",
      "[DEBUG] Nekmo/amazon-dash: 50 / 89\n",
      "Nekmo/amazon-dash took 11.257229328155518 seconds\n",
      "[DEBUG] lepture/flask-oauthlib: 50 / 66\n",
      "lepture/flask-oauthlib took 5.267605781555176 seconds\n",
      "[DEBUG] jterrace/pyssim: 20 / 33\n",
      "jterrace/pyssim took 6.25580096244812 seconds\n",
      "[DEBUG] yashaka/selene: 50 / 86\n",
      "yashaka/selene took 23.8922336101532 seconds\n",
      "[DEBUG] bakwc/PySyncObj: 50 / 135\n",
      "bakwc/PySyncObj took 6.2046263217926025 seconds\n",
      "[DEBUG] egh/ledger-autosync: 50 / 79\n",
      "egh/ledger-autosync took 4.592649698257446 seconds\n",
      "[DEBUG] google/pybadges: 16 / 35\n",
      "google/pybadges took 3.131618022918701 seconds\n",
      "[DEBUG] mwarkentin/django-watchman: 50 / 111\n",
      "mwarkentin/django-watchman took 7.094856023788452 seconds\n",
      "[DEBUG] openvenues/pypostal: 13 / 42\n",
      "openvenues/pypostal took 3.729708433151245 seconds\n",
      "[DEBUG] pyca/pyopenssl: 50 / 144\n",
      "pyca/pyopenssl took 22.15355634689331 seconds\n",
      "[DEBUG] zqfang/GSEApy: 50 / 145\n",
      "zqfang/GSEApy took 54.55784249305725 seconds\n",
      "[DEBUG] google/brotli: 43 / 106\n",
      "google/brotli took 63.66305112838745 seconds\n",
      "[DEBUG] hydrosquall/tiingo-python: 50 / 119\n",
      "hydrosquall/tiingo-python took 14.037811279296875 seconds\n",
      "[DEBUG] 3DLIRIOUS/MeshLabXML: 7 / 45\n",
      "3DLIRIOUS/MeshLabXML took 5.742558240890503 seconds\n",
      "[DEBUG] domainaware/parsedmarc: 50 / 91\n",
      "domainaware/parsedmarc took 18.599673986434937 seconds\n",
      "[DEBUG] maxcountryman/flask-uploads: 21 / 37\n",
      "maxcountryman/flask-uploads took 3.3264169692993164 seconds\n",
      "[DEBUG] mental32/spotify.py: 50 / 82\n",
      "mental32/spotify.py took 5.4326794147491455 seconds\n",
      "[DEBUG] Azure/Azure-MachineLearning-ClientLibrary-Python: 9 / 27\n",
      "Azure/Azure-MachineLearning-ClientLibrary-Python took 2.7069523334503174 seconds\n",
      "[DEBUG] Qiskit/qiskit-terra: 50 / 192\n",
      "Qiskit/qiskit-terra took 82.22135353088379 seconds\n",
      "[DEBUG] funilrys/PyFunceble: 50 / 106\n",
      "funilrys/PyFunceble took 19.333075046539307 seconds\n",
      "[DEBUG] nats-io/asyncio-nats: 50 / 138\n",
      "nats-io/asyncio-nats took 8.18150782585144 seconds\n",
      "[DEBUG] pgjones/hypercorn: 50 / 75\n",
      "pgjones/hypercorn took 5.621072769165039 seconds\n",
      "[DEBUG] jrfonseca/xdot.py: 50 / 83\n",
      "jrfonseca/xdot.py took 6.101203680038452 seconds\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "data = []\n",
    "\n",
    "size = len(repodf['repo']) // 100\n",
    "\n",
    "def f(repo):\n",
    "  start = time.time()\n",
    "  df = parse_repo_commits(repo)\n",
    "  end = time.time()\n",
    "  print(f\"{repo} took {end-start} seconds\")\n",
    "  return df\n",
    "\n",
    "for i in range (100):\n",
    "    pool = multiprocessing.Pool()\n",
    "    outputs = pool.map(f, repodf['repo'][size*i:min(size*(i+1), len(repodf['repo']))])\n",
    "    pd.concat(outputs, ignore_index=True).to_pickle(f\"{root}/repos/data{i}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bfe004",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "04bfe004",
    "outputId": "9b89d00f-ec36-4eb7-eaca-240bff0d78b3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>hash</th>\n",
       "      <th>commit_messsage</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soimort/you-get</td>\n",
       "      <td>5a12118c836b0b9a7a2f8bdbed25be9aa2ca7831</td>\n",
       "      <td>[\"add\", \"param\", \"postfix\", \"to\", \"postfix\", \"...</td>\n",
       "      <td>[\"&lt;file&gt;\", \"\\n\", \"output\", \"filename\", \"= \", \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soimort/you-get</td>\n",
       "      <td>3f47a215bf5f73e73cd7aa607b340a7b68b9bd3d</td>\n",
       "      <td>[\"fix\", \"the\", \"name\", \"m\", \"u\", \"is\", \"not\", ...</td>\n",
       "      <td>[\"&lt;file&gt;\", \"\\n\", \"cookies\", \"= \", \"none\", \"\\n\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soimort/you-get</td>\n",
       "      <td>424b555500e65da0533d369a80562bb93907ec9a</td>\n",
       "      <td>[\"fix\", \"zhihu\", \"extractor\", \"comment\", \"ld\"]</td>\n",
       "      <td>[\"&lt;file&gt;\", \"\\n\", \"def\", \"zhihu\", \"download\", \"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              repo  ...                                               diff\n",
       "0  soimort/you-get  ...  [\"<file>\", \"\\n\", \"output\", \"filename\", \"= \", \"...\n",
       "1  soimort/you-get  ...  [\"<file>\", \"\\n\", \"cookies\", \"= \", \"none\", \"\\n\"...\n",
       "2  soimort/you-get  ...  [\"<file>\", \"\\n\", \"def\", \"zhihu\", \"download\", \"...\n",
       "\n",
       "[3 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(f\"{root}/data.pkl\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FmB-28AA2Vh6",
   "metadata": {
    "id": "FmB-28AA2Vh6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Dataset Generation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
