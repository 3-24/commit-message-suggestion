{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Dataset Generation.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TySV2A3KyKzL",
        "outputId": "819a0ea8-017d-4bf3-e309-48ceb9a7089b"
      },
      "source": [
        "# mount drive https://datascience.stackexchange.com/questions/29480/uploading-images-folder-from-my-system-into-google-colab\n",
        "# login with your google account and type authorization code to mount on your googlbie drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "root = '/gdrive/My Drive/CS492I/project'"
      ],
      "id": "TySV2A3KyKzL",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a5ade31"
      },
      "source": [
        "## 1. Collect CodeSearchNet Repositories"
      ],
      "id": "8a5ade31"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c06bb109"
      },
      "source": [
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "pd.set_option('max_colwidth',300)\n",
        "from pprint import pprint"
      ],
      "id": "c06bb109",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c50cf9b",
        "outputId": "b4f14afd-fa30-4241-d6f6-043d0bf3d852"
      },
      "source": [
        "!wget https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/python.zip\n",
        "!mkdir CodeSearchNet\n",
        "!unzip python.zip -d CodeSearchNet"
      ],
      "id": "4c50cf9b",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-03 05:33:04--  https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/python.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.145.45\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.145.45|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 940909997 (897M) [application/zip]\n",
            "Saving to: ‘python.zip’\n",
            "\n",
            "python.zip          100%[===================>] 897.32M  46.1MB/s    in 21s     \n",
            "\n",
            "2021-12-03 05:33:25 (43.4 MB/s) - ‘python.zip’ saved [940909997/940909997]\n",
            "\n",
            "Archive:  python.zip\n",
            "   creating: CodeSearchNet/python/\n",
            "   creating: CodeSearchNet/python/final/\n",
            "   creating: CodeSearchNet/python/final/jsonl/\n",
            "   creating: CodeSearchNet/python/final/jsonl/train/\n",
            "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_9.jsonl.gz  \n",
            "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_12.jsonl.gz  \n",
            "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_10.jsonl.gz  \n",
            "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_0.jsonl.gz  \n",
            "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_6.jsonl.gz  \n",
            "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_2.jsonl.gz  \n",
            "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_4.jsonl.gz  \n",
            "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_8.jsonl.gz  \n",
            "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_11.jsonl.gz  \n",
            "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_5.jsonl.gz  \n",
            "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_13.jsonl.gz  \n",
            "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_3.jsonl.gz  \n",
            "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_1.jsonl.gz  \n",
            "  inflating: CodeSearchNet/python/final/jsonl/train/python_train_7.jsonl.gz  \n",
            "   creating: CodeSearchNet/python/final/jsonl/test/\n",
            "  inflating: CodeSearchNet/python/final/jsonl/test/python_test_0.jsonl.gz  \n",
            "   creating: CodeSearchNet/python/final/jsonl/valid/\n",
            "  inflating: CodeSearchNet/python/final/jsonl/valid/python_valid_0.jsonl.gz  \n",
            "  inflating: CodeSearchNet/python_dedupe_definitions_v2.pkl  \n",
            "  inflating: CodeSearchNet/python_licenses.pkl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2847085c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "658c813b-2b7f-4c1b-b552-a36514e705b1"
      },
      "source": [
        "python_files = sorted(Path('CodeSearchNet/python').glob('**/*.gz'))\n",
        "print(python_files)"
      ],
      "id": "2847085c",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PosixPath('CodeSearchNet/python/final/jsonl/test/python_test_0.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_0.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_1.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_10.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_11.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_12.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_13.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_2.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_3.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_4.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_5.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_6.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_7.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_8.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/train/python_train_9.jsonl.gz'), PosixPath('CodeSearchNet/python/final/jsonl/valid/python_valid_0.jsonl.gz')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aa7dbe1"
      },
      "source": [
        "columns_long_list = ['repo', 'path', 'url', 'code', \n",
        "                     'code_tokens', 'docstring', 'docstring_tokens', \n",
        "                     'language', 'partition']\n",
        "\n",
        "def jsonl_list_to_dataframe(file_list, columns=columns_long_list):\n",
        "    \"\"\"Load a list of jsonl.gz files into a pandas DataFrame.\"\"\"\n",
        "    return pd.concat([pd.read_json(f, \n",
        "                                   orient='records', \n",
        "                                   compression='gzip',\n",
        "                                   lines=True)[columns] \n",
        "                      for f in file_list], sort=False)"
      ],
      "id": "8aa7dbe1",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be6c1c77"
      },
      "source": [
        "pydf = jsonl_list_to_dataframe(python_files, columns=['repo'])\n",
        "pydf = pydf.drop_duplicates().reset_index(drop=True)\n",
        "pydf.to_pickle(f\"{root}/repos.pkl\")"
      ],
      "id": "be6c1c77",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d0559c4"
      },
      "source": [
        "## 2. Collect diff and commits"
      ],
      "id": "1d0559c4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ee24339",
        "outputId": "4ed05501-9298-4c2c-c5d6-3ced823e2e4c"
      },
      "source": [
        "!pip install pydriller\n",
        "!pip install pandas\n",
        "!pip install spacy"
      ],
      "id": "8ee24339",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydriller\n",
            "  Downloading PyDriller-2.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting gitpython\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 11.7 MB/s \n",
            "\u001b[?25hCollecting lizard\n",
            "  Downloading lizard-1.17.9-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from pydriller) (2018.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython->pydriller) (3.10.0.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 599 kB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, lizard, gitpython, pydriller\n",
            "Successfully installed gitdb-4.0.9 gitpython-3.1.24 lizard-1.17.9 pydriller-2.0 smmap-5.0.0\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.10.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72e76292"
      },
      "source": [
        "from pydriller import *\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import spacy\n",
        "import re\n",
        "from itertools import chain\n",
        "import json"
      ],
      "id": "72e76292",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "845d5eb7",
        "outputId": "3d8e8645-3a9f-4d76-c44b-9e72af9aab5d"
      },
      "source": [
        "repodf = pd.read_pickle(f\"{root}/repos.pkl\")\n",
        "print(repodf.shape)\n",
        "spacy_tokenizer = spacy.load(\"en_core_web_sm\")\n",
        "print(repodf)"
      ],
      "id": "845d5eb7",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13590, 1)\n",
            "                                 repo\n",
            "0                     soimort/you-get\n",
            "1                      apache/airflow\n",
            "2                      pytorch/vision\n",
            "3                      asciimoo/searx\n",
            "4              tensorflow/probability\n",
            "...                               ...\n",
            "13585         praekelt/python-ambient\n",
            "13586                 zenreach/py-era\n",
            "13587  TakesxiSximada/custom_settings\n",
            "13588            openpermissions/bass\n",
            "13589               xnuinside/clifier\n",
            "\n",
            "[13590 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "449680fc"
      },
      "source": [
        "def basic_filter(message):\n",
        "    return message.split(\"\\n\", 1)[0].strip()\n",
        "\n",
        "# Remove [label] in front of commit if exists\n",
        "def label_filter(message):\n",
        "    if (message.startswith('[')):\n",
        "        end_bracket_index = message.find(']')\n",
        "        if (end_bracket_index == -1):\n",
        "            return None\n",
        "        return message[:end_bracket_index+1]\n",
        "    return message\n",
        "\n",
        "def camel_case_split(str):\n",
        "    return re.findall(r'[A-Z](?:[a-z]+|[A-Z]*(?=[A-Z]|$))', str)\n",
        "\n",
        "def case_splitter(token):\n",
        "    return list(map(lambda x: x.lower(), camel_case_split(token[0].upper() + token[1:])))\n",
        "\n",
        "\n",
        "def split_by_quote(diff):\n",
        "    text_list = [(0,0)]\n",
        "    quote_state = 0 #[\"out\",\"single\",\"double\",\"Single\",\"Double\",\"quote\"]\n",
        "    i=0\n",
        "    while i<len(diff):\n",
        "      if diff[i] == \"\\\\\":i+=1\n",
        "      elif (diff[i] == \"\\n\" and quote_state == 5) or (diff[i] == '#' and quote_state == 0):\n",
        "        text_list.append((quote_state,i))\n",
        "        quote_state = abs(5-quote_state)\n",
        "      elif diff[i] == '\"':\n",
        "        if i+2<len(diff) and diff[i:i+3]=='\"\"\"' and (quote_state == 0 or quote_state ==4):\n",
        "          text_list.append((quote_state,i+max(quote_state-1,0)))\n",
        "          quote_state = abs(4-quote_state)\n",
        "          i+=2\n",
        "        elif quote_state == 0 or quote_state == 2:\n",
        "          text_list.append((quote_state,i+max(quote_state-1,0)))\n",
        "          quote_state = abs(2-quote_state)\n",
        "      elif diff[i] == \"'\":\n",
        "        if i+2<len(diff) and diff[i:i+3] == \"'''\" and (quote_state == 0 or quote_state == 3):\n",
        "          text_list.append((quote_state,i+quote_state))\n",
        "          quote_state = abs(3-quote_state)\n",
        "          i+=2\n",
        "        elif quote_state == 0 or quote_state == 1:\n",
        "          text_list.append((quote_state,i+quote_state))\n",
        "          quote_state = abs(1-quote_state)\n",
        "      i+=1\n",
        "    text_list.append((quote_state,i))\n",
        "    return [(text_list[i][0]==0,diff[text_list[i-1][1]:text_list[i][1]]) for i in range(1,len(text_list))]\n",
        "  \n",
        "\n",
        "def diff_tokenizer(diff_text):\n",
        "    diff = '\\n'.join(map(lambda x: x[1], filter(lambda y: y[0] % 2 == 0, enumerate(diff_text.split(\"@@\")))))\n",
        "    diff = diff.replace('\\n+', '\\n<add>').replace('\\n-', '\\n<del>')\n",
        "    diff = re.sub(r\"(?:\\n[ \\t\\r\\f\\v]*)+\",\"\\n\",diff) #Join continuous row change\n",
        "    quote_split = split_by_quote(diff)\n",
        "    token_regex = r\"\"\"(?x)\n",
        "      <(?:add|del)>   #Filtered eariler\n",
        "    |(?:[-+*/^&~|=%!<>@?$][\\s]*)+     #Sequence of symbols\n",
        "    |[\\n]                    #Change row\n",
        "    |[a-zA-Z]+               #General text\n",
        "    |[0-9]+                  #Number\n",
        "    \"\"\"\n",
        "    string_regex = r\"\"\"(?x)\n",
        "    <(?:add|del)>\n",
        "    |[\\n]\n",
        "    |[a-zA-Z]+\n",
        "    \"\"\"\n",
        "    #'\"`,.;:()[]{}_ not included\n",
        "    token_initial = chain.from_iterable(map(lambda a: nltk.tokenize.regexp_tokenize(a[1],token_regex) if a[0] else nltk.tokenize.regexp_tokenize(a[1],string_regex), quote_split))\n",
        "    token_camel_case_split = chain.from_iterable(map(lambda a: case_splitter(a) if 97<=ord(a[0].lower())<122 else [a], token_initial))\n",
        "    return token_camel_case_split\n",
        "\n",
        "\n",
        "def parse_repo_commits(repo_name, commit_limit=50):\n",
        "    data = []\n",
        "    commit_count = 0\n",
        "    for commit in Repository(\n",
        "        f\"https://github.com/{repo_name}\",\n",
        "        only_modifications_with_file_types=[\".py\"],\n",
        "        only_no_merge=True,\n",
        "        order='reverse'\n",
        "    ).traverse_commits():\n",
        "        if (commit_count >= commit_limit): break\n",
        "        line = basic_filter(commit.msg)\n",
        "        line = label_filter(line)\n",
        "        if (line is None):\n",
        "            print(f\"[DEBUG] Label filter return None for repo {repo} and hash {commit.hash}\")\n",
        "        \n",
        "        line = line.replace('_', ' ').replace('.', ' ')\n",
        "\n",
        "        # ignore mentions, non-English, github issue #\n",
        "        if (len(re.findall(r\"[^a-zA-Z0-9: ]\", line)) != 0):\n",
        "          continue\n",
        "        \n",
        "        tokens = spacy_tokenizer(line)\n",
        "        \n",
        "        # VERB filter\n",
        "        if (tokens[0].pos_ != 'VERB'):\n",
        "            continue\n",
        "        \n",
        "        commit_tokens = list(chain.from_iterable(map(lambda token: case_splitter(token.text), tokens)))\n",
        "        \n",
        "        if (len(commit_tokens) < 3 or len(commit_tokens) > 30):\n",
        "            continue\n",
        "\n",
        "        # Check if changed files are python\n",
        "        file_failed = False\n",
        "        count_diff_lines = 0\n",
        "\n",
        "        for mf in commit.modified_files:\n",
        "            if (not mf.filename.endswith(\".py\")):\n",
        "                file_failed = True\n",
        "                break\n",
        "            count_diff_lines += mf.added_lines + mf.deleted_lines\n",
        "        \n",
        "        if (file_failed):\n",
        "            continue\n",
        "        \n",
        "        if(count_diff_lines > 50):\n",
        "            continue\n",
        "        \n",
        "        # Create diff tokens\n",
        "        diff_tokens = []\n",
        "        for f in commit.modified_files:\n",
        "          diff_tokens.append (['<file>'])\n",
        "          diff_tokens.append(diff_tokenizer(f.diff))\n",
        "\n",
        "        diff_whole_tokens = list(chain.from_iterable(diff_tokens))\n",
        "\n",
        "        data.append([repo_name, commit.hash, json.dumps(commit_tokens), json.dumps(diff_whole_tokens)])\n",
        "        commit_count += 1\n",
        "\n",
        "    return pd.DataFrame(data, columns=[\"repo\", \"hash\", \"commit_messsage\", \"diff\"])"
      ],
      "id": "449680fc",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "b2854419",
        "outputId": "28c2b68a-6bb2-4ca1-963c-556e9da0435c"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "df = parse_repo_commits(\"soimort/you-get\")\n",
        "#df = parse_repo_commits(\"tensorflow/probability\")\n",
        "end = time.time()\n",
        "print(end - start)\n",
        "df.head(3)"
      ],
      "id": "b2854419",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19.178345680236816\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>repo</th>\n",
              "      <th>hash</th>\n",
              "      <th>commit_messsage</th>\n",
              "      <th>diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>soimort/you-get</td>\n",
              "      <td>439354e730d8b864de9401536c93220467ccb355</td>\n",
              "      <td>[\"add\", \"hdr\", \"support\", \"for\", \"bilibili\"]</td>\n",
              "      <td>[\"&lt;file&gt;\", \"\\n\", \"class\", \"bilibili\", \"video\",...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>soimort/you-get</td>\n",
              "      <td>4a9d2c1e13b8918deba39af515d315b60e545422</td>\n",
              "      <td>[\"add\", \"fake\", \"header\"]</td>\n",
              "      <td>[\"&lt;file&gt;\", \"\\n\", \"def\", \"netease\", \"song\", \"do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>soimort/you-get</td>\n",
              "      <td>205470ec116654608ddd97390bd885ba6df100b1</td>\n",
              "      <td>[\"add\", \"support\", \"for\", \"socks\", \"proxy\", \"u...</td>\n",
              "      <td>[\"&lt;file&gt;\", \"\\n\", \"def\", \"load\", \"cookies\", \"co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              repo  ...                                               diff\n",
              "0  soimort/you-get  ...  [\"<file>\", \"\\n\", \"class\", \"bilibili\", \"video\",...\n",
              "1  soimort/you-get  ...  [\"<file>\", \"\\n\", \"def\", \"netease\", \"song\", \"do...\n",
              "2  soimort/you-get  ...  [\"<file>\", \"\\n\", \"def\", \"load\", \"cookies\", \"co...\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Dn9Co_Izwuf"
      },
      "source": [
        "# 3. Create whole dataset via Multiprocessing"
      ],
      "id": "3Dn9Co_Izwuf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f65faf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bacdd33e-0c26-49c3-80cd-502495fb4f92"
      },
      "source": [
        "import multiprocessing\n",
        "\n",
        "data = []\n",
        "\n",
        "def f(repo):\n",
        "    start = time.time()\n",
        "    df = parse_repo_commits(repo)\n",
        "    #df.to_pickle(f\"./repos/{repo.replace('/', '+')}.pkl\")\n",
        "    end = time.time()\n",
        "    print(f\"{repo} took {end-start} seconds\")\n",
        "    return df\n",
        "\n",
        "pool = multiprocessing.Pool()\n",
        "outputs = pool.map(f, repodf['repo'][:3])\n",
        "pd.concat(outputs).to_pickle(f\"{root}/data.pkl\")"
      ],
      "id": "0f65faf9",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "soimort/you-get Done\n",
            "pytorch/vision Done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Process ForkPoolWorker-1:\n",
            "Process ForkPoolWorker-2:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
            "    return list(map(*args))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
            "    res = self._reader.recv_bytes()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pydriller/repository.py\", line 240, in _iter_commits\n",
            "    if self._conf.is_commit_filtered(commit):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pydriller/repository.py\", line 233, in traverse_commits\n",
            "    for commit in job.result():\n",
            "  File \"<ipython-input-9-3b417c65f674>\", line 81, in parse_repo_commits\n",
            "    order='reverse'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b9bbe713e615>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepodf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'repo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{root}/data.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pydriller/utils/conf.py\", line 282, in _has_modification_with_file_type\n",
            "    for mod in commit.modified_files:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pydriller/utils/conf.py\", line 267, in is_commit_filtered\n",
            "    if not self._has_modification_with_file_type(commit):\n",
            "  File \"<ipython-input-11-b9bbe713e615>\", line 6, in f\n",
            "    df = parse_repo_commits(repo)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pydriller/domain/commit.py\", line 684, in _get_modifications\n",
            "    self._c_object, create_patch=True, **options\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pydriller/domain/commit.py\", line 668, in modified_files\n",
            "    self._modifications = self._get_modifications()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/git/diff.py\", line 175, in diff\n",
            "    index = diff_method(self.repo, proc)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/git/diff.py\", line 497, in _index_from_patch_format\n",
            "    None, None, None))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/git/diff.py\", line 309, in __init__\n",
            "    for submodule in repo.submodules:\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/git/repo/base.py\", line 368, in submodules\n",
            "    return Submodule.list_items(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/git/util.py\", line 1103, in list_items\n",
            "    out_list.extend(cls.iter_items(repo, *args, **kwargs))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/git/objects/submodule/base.py\", line 1267, in iter_items\n",
            "    if pc != repo.commit():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/git/repo/base.py\", line 535, in commit\n",
            "    return self.head.commit\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/git/refs/symbolic.py\", line 217, in _get_commit\n",
            "    obj = self._get_object()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/git/refs/symbolic.py\", line 210, in _get_object\n",
            "    return Object.new_from_sha(self.repo, hex_to_bin(self.dereference_recursive(self.repo, self.path)))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/git/objects/base.py\", line 85, in new_from_sha\n",
            "    oinfo = repo.odb.info(sha1)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/git/db.py\", line 43, in info\n",
            "    hexsha, typename, size = self._git.get_object_header(bin_to_hex(binsha))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/git/cmd.py\", line 1252, in get_object_header\n",
            "    return self.__get_object_header(cmd, ref)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/git/cmd.py\", line 1238, in __get_object_header\n",
            "    cmd.stdin.flush()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04bfe004"
      },
      "source": [
        "df = pd.read_pickle(\"data.pkl\")\n",
        "df.head(3)"
      ],
      "id": "04bfe004",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hlgSt6J6Tvr"
      },
      "source": [
        ""
      ],
      "id": "5hlgSt6J6Tvr",
      "execution_count": null,
      "outputs": []
    }
  ]
}